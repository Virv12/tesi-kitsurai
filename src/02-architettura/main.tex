\section{Architettura}
\label{sec:architettura}

% 2.2.1 Puoi spiegare forse meglio lo stato preparata che lo butti li e basta
% 2.4 Disegnino?
% 2.6 Disegnino?

Il database è organizzato in \emph{tabelle}, ciascuna identificata da un UUID versione~7~\cite{rfc9562}.
Ogni tabella contiene coppie chiave-valore, dove sia le chiavi sia i valori sono array di byte.

Un sistema Kitsurai opera su un \emph{cluster}, composto da un insieme statico di nodi, i quali possono occasionalmente risultare non disponibili.
Un \emph{nodo} corrisponde a un'istanza del programma, eseguibile su una macchina fisica o virtuale.
Ciascun nodo può essere etichettato con una stringa che identifica la sua \emph{Availability Zone} (vedi sezione~\ref{subsec:availability-zones}).
Ogni nodo mantiene una copia dei metadati di tutte le tabelle.

\subsection{Interfaccia}
\label{subsec:interfaccia}

Sono supportate quattro operazioni principali:
\begin{itemize}
    \item \texttt{create-table}: crea una nuova tabella con i parametri specificati.
    \item \texttt{delete-table}: cancella una tabella esistente.
    \item \texttt{get}: recupera il valore associato a una chiave in una tabella.
    \item \texttt{set}: imposta il valore associato a una chiave in una tabella.
\end{itemize}

Ognuna di queste richieste può essere inviata a un nodo a scelta del client, che funge da \emph{router} per inoltrare la richiesta ai nodi responsabili della tabella specificata.

\subsection{Tabelle}
\label{subsec:tabelle}

Ogni tabella ha quattro parametri specificati dall'utente al momento della creazione:
\begin{itemize}
    \item \texttt{bandwidth} o \texttt{b}: il numero di richieste al secondo che il sistema deve garantire per la tabella.
    \item \texttt{n}: il fattore di replicazione per ogni coppia chiave-valore.
    \item \texttt{read\_concern} o \texttt{r}: il numero minimo di nodi che devono rispondere con successo a una richiesta di lettura.
    \item \texttt{write\_concern} o \texttt{w}: il numero minimo di nodi che devono rispondere con successo a una richiesta di scrittura.
\end{itemize}

E altri quattro parametri calcolati automaticamente:
\begin{itemize}
    \item \texttt{id}: un UUIDv7 che identifica la tabella, generato al momento della creazione.
    \item $\Sigma$: la banda effettiva della tabella considerando l'effetto della replicazione, calcolata come $\displaystyle \Sigma = b \cdot n$.
    \item \texttt{responsible\_nodes}: l'elenco dei nodi responsabili per la tabella, scelti in modo da garantire la replicazione e la disponibilità dei dati.
    \item $b_i$: la banda allocata a ciascun nodo $i$ responsabile della tabella, tale che $\displaystyle \sum b_i = \Sigma$.
\end{itemize}

Ogni tabella è gestita da un insieme di nodi, chiamati \emph{nodi responsabili}, scelti in modo da garantire la replicazione e la disponibilità dei dati.
In ogni nodo, una tabella può trovarsi in uno dei tre stati: \emph{preparata}, \emph{creata} o \emph{cancellata}.
Le tabelle possono solo progredire di stato, nell'ordine: \emph{preparata} $\rightarrow$ \emph{creata} $\rightarrow$ \emph{cancellata}.
Una tabella si considera \emph{creata} quando tutti i nodi responsabili la considerano tale; si considera \emph{cancellata} quando almeno un nodo la contrassegna come tale.
Lo stato di una tabella viene sincronizzato tra i nodi tramite il protocollo di \emph{Gossip} (vedi sezione~\ref{subsec:gossip}).

\subsubsection{Creazione e Cancellazione}
\label{subsubsec:creazione-cancellazione}

Per creare una tabella, si seguono i seguenti passaggi:
\begin{enumerate}
    \item Il client si connette a un nodo a sua scelta (detto \emph{router}) e invia i parametri \texttt{b}, \texttt{n}, \texttt{r} e \texttt{w} della tabella.
    \item Il router genera un \texttt{id} per la tabella e calcola la banda effettiva $\Sigma = b \cdot n$, per tenere conto della replicazione.
    \item Il router richiede agli altri nodi la banda disponibile per la nuova tabella, evitando di allocare più di $b$ su un singolo nodo, garantendo così che la tabella venga replicata esattamente $n$ volte. Se un nodo risponde a questa richiesta segna la tabella come \emph{preparata}.
    \item Una volta ottenuta sufficiente banda (almeno $\Sigma$), il router definisce l'elenco dei nodi responsabili e le rispettive quote $b_i$.
    \item Il router richiede ai nodi precedentemente interrogati di eseguire il \texttt{commit} della tabella, su questi nodi la tabella entra nello stato \emph{creata}.
    \item Se tutti i nodi effettuano il \texttt{commit}, la creazione ha successo e il router restituisce al client l'\texttt{id} della nuova tabella.
\end{enumerate}

Se un nodo riceve una richiesta di preparazione per una nuova tabella, ma non riceve un \texttt{commit} entro un certo timeout, segnerà la tabella come \emph{cancellata}.
Questo garantisce che, in caso di errori durante la creazione, la tabella non rimanga in uno stato indefinito che comporterebbe perdita di banda allocata.

Per cancellare una tabella, è sufficiente che un nodo la contrassegni come \emph{cancellata}; successivamente, grazie al protocollo di \emph{Gossip} (vedi sezione~\ref{subsec:gossip}), gli altri nodi si sincronizzeranno e la tabella sarà considerata cancellata da tutti.

\subsubsection{Metadati}
\label{subsubsec:metadati}

Il database contiene una tabella speciale, non accessibile dagli utenti, identificata da uno UUIDv8 generato dai byte \texttt{kitsuraimetadata}.
Questa tabella contiene i metadati di tutte le tabelle create nel cluster, inclusi i relativi parametri e i nodi responsabili.
Grazie a ciò, ogni nodo può comportarsi come router nelle richieste di \texttt{get} e \texttt{set}.
La tabella dei metadati, identificata da uno UUIDv8, non può entrare in conflitto con gli UUIDv7 generati per le tabelle degli utenti.

\subsection{Gossip}
\label{subsec:gossip}

Ogni nodo del cluster avvia uno scambio di \emph{gossip} con un peer scelto casualmente ogni secondo.
Durante lo scambio, i due nodi sincronizzano i metadati delle tabelle \emph{create} e \emph{cancellate}, ma non di quelle \emph{in preparazione}.
Se una stessa tabella si trova in stati diversi su due nodi, prevale quello che rappresenta un progresso maggiore rispetto all'altro.
L'utilizzo di un Merkle tree consente ai nodi di identificare rapidamente le tabelle divergenti e sincronizzarsi solo su quelle.
Se il peer non è disponibile, lo scambio fallisce.
Il gossip permette al sistema di raggiungere la coerenza dei metadati tra i nodi anche in presenza di nodi offline o errori di rete.

\subsection{Anello di replicazione}
\label{subsec:anello-replicazione}

Per garantire la disponibilità del database, vogliamo che ogni chiave sia replicata su più nodi rispettando i seguenti requisiti:

\begin{itemize}
    \item Ogni chiave è replicata su \texttt{n} nodi distinti tra quelli responsabili della tabella, per garantire la disponibilità dei dati anche in caso di guasti a uno o più nodi.
    \item Ogni nodo $i$ ha una banda allocata proporzionale alla sua capacità, al fine di garantire una distribuzione equa del carico tra i nodi. Quindi, dato che ogni chiave è replicata su \texttt{n} nodi distinti, ogni nodo contiene una frazione $\displaystyle n \cdot \frac{b_i}{\Sigma} = \frac{b_i}{b}$ del totale delle chiavi.
\end{itemize}

Per soddisfare questi requisiti, definiamo l'\emph{anello di replicazione} come un array circolare di dimensione $\Sigma$.
Per ogni posizione nell'anello, assegniamo un nodo $i$ in modo tale che:

\begin{itemize}
    \item Ogni intervallo di lunghezza $n$ nell'anello contenga nodi distinti.
    \item Ogni nodo $i$ occupi esattamente $b_i$ posizioni nell'anello.
\end{itemize}

Data una chiave, calcoliamo il suo hash (utilizzando \texttt{XXH3}\footnote{\url{https://xxhash.com}}, un algoritmo di hash veloce e non crittografico) e troviamo la posizione corrispondente nell'anello.
La chiave viene assegnata ai \texttt{n} nodi immediatamente successivi alla posizione calcolata.
Se le proprietà dell'anello sono rispettate, anche i requisiti di disponibilità e bilanciamento della banda risultano garantiti.

\subsubsection{Costruzione esplicita}
\label{subsubsec:costruzione-esplicita}

I nodi sono assegnati all'anello in modo iterativo, partendo dal primo nodo.
Ogni nodo è assegnato a $b_i$ posizioni, proseguendo dall'ultima posizione assegnata al nodo precedente (o da una posizione arbitraria nel caso del primo nodo), e occupando uno slot ogni $n$ posizioni.
Se lo slot è già occupato da un altro nodo, si salta al successivo.
Poiché ogni nodo ha banda $b_i \leq b$, e l'anello ha dimensione $\Sigma = b \cdot n$, è garantito che ogni nodo possa essere assegnato a $b_i$ posizioni senza svolgere un ciclo completo dell'anello, quindi tutte le posizioni sono distanti tra loro di almeno $n$ posizioni.
Quindi questa costruzione rispetta le proprietà sopra descritte per l'\emph{anello di replicazione}.

\begin{samepage}
\noindent In pseudocodice, la costruzione dell'anello può essere rappresentata come segue:
\begin{minted}{python}
def build_ring(table):
    sigma = table.bandwidth * table.n
    ring = [None] * sigma
    current_position = 0

    for node in table.responsible_nodes:
        for _ in range(node.bandwidth):
            if ring[current_position] is not None:
                current_position = (current_position + 1) % sigma
            ring[current_position] = node
            current_position = (current_position + table.n) % sigma

    return ring
\end{minted}
\end{samepage}

Questa costruzione richiede $O(\Sigma)$ tempo e spazio.

\subsubsection{Costruzione implicita}
\label{subsubsec:costruzione-implicita}

Poiché la banda allocata può essere considerevolmente elevata, la costruzione esplicita di un anello conforme ai criteri potrebbe risultare costosa.
Per evitarla, cerchiamo un algoritmo che calcola direttamente il nodo assegnato a una posizione $i$ nell'anello.
Chiamiamo $o_i$ l'iterazione alla quale viene assegnata l'$i$-esima posizione.
Osserviamo che la costruzione esplicita assegna i nodi nel seguente ordine: per primi i multipli di $n$ in ordine crescente, poi i numeri congruenti a $1$ modulo $n$ in ordine crescente, poi i numeri congruenti a $2$ modulo $n$ in ordine crescente, e così via fino a $n-1$, ne segue che $\displaystyle o_i = \left\lfloor \frac{i}{n} \right\rfloor + (i \bmod n) \cdot b$.
Ora dobbiamo trovare quale è stato l'$o_i$-esimo nodo assegnato, ci basta trovare il primo nodo $x$ tale che $\displaystyle \sum_{j=0}^{x} b_j > o_i$.

In pseudocodice, l'algoritmo per trovare il nodo assegnato a una posizione $i$ nell'anello può essere rappresentato come segue:
\begin{minted}{python}
def get_node_at_position(table, i):
    n = table.n
    b = table.bandwidth
    o_i = (i // n) + (i % n) * b

    sum = 0
    for node in enumerate(table.responsible_nodes):
        sum += node.bandwidth
        if sum > o_i:
            return node
\end{minted}

Possiamo quindi calcolare il nodo assegnato a una posizione $i$ nell'anello in tempo lineare rispetto al numero di nodi responsabili e memoria costante, senza dover costruire esplicitamente l'anello.

L'algoritmo si può ottimizzare ulteriormente utilizzando una ricerca binaria sulle somme prefisse di $b_i$, assumendo che siano già calcolate e memorizzate.
L'algoritmo esegue quindi in tempo logaritmico rispetto al numero di nodi responsabili, richiedendo memoria lineare per le somme prefisse.

\subsubsection{Condizioni di esistenza}
\label{subsubsec:esistenza}

Come mostrato, se ogni nodo soddisfa la condizione $b_i \leq b$ (come garantito durante la creazione della tabella), allora l'anello di replicazione esiste e può essere costruito.
Tuttavia, se queste condizioni non sono rispettate, l'anello non può esistere: non è possibile assegnare le chiavi in modo che rispettino simultaneamente le condizioni di replica e di banda.

Per contraddizione, supponiamo che un nodo $k$ abbia banda $b_k > b$.
Allora tale nodo conterrà $\displaystyle \frac{b_k}{b} > 1$ del totale delle chiavi, il che è assurdo.

Questo dimostra che le condizioni imposte durante la creazione della tabella sono \emph{necessarie e sufficienti} per il corretto funzionamento del sistema.

\subsection{Operazioni \texttt{get} e \texttt{set}}
\label{subsec:get-set}

Per leggere o scrivere una chiave, si seguono i seguenti passaggi:
\begin{enumerate}
    \item Il client si connette a un nodo a sua scelta (detto \emph{router}) e invia la chiave e il valore (se si tratta di una scrittura).
    \item Il router calcola l'hash della chiave e determina gli \texttt{n} nodi responsabili per quella chiave.
    \item Il router invia la richiesta di lettura o scrittura ai nodi responsabili.
    \item I nodi rispondono con il valore richiesto o confermano la scrittura.
    \item Il router aggrega le risposte e restituisce al client i primi \texttt{r} (o \texttt{w}) risultati disponibili.
\end{enumerate}

Se meno di \texttt{r} (o \texttt{w}) nodi rispondono con successo, l'operazione fallisce e il client riceve un errore.

\subsection{Availability Zones}
\label{subsec:availability-zones}

Per garantire la disponibilità del database, ogni nodo può essere etichettato con una stringa che identifica la sua \emph{Availability Zone} (\texttt{AZ}).
Due nodi appartenenti alla stessa \texttt{AZ} non possono essere scelti per replicare la stessa chiave.
Per garantire che le chiavi siano replicate in modo da essere disponibili anche in caso di guasti a un'intera \texttt{AZ}, modifichiamo l'algoritmo di distribuzione delle chiavi:
\begin{itemize}
    \item durante la creazione della tabella, il router non deve allocare più di \texttt{b} banda da nodi nella stessa \texttt{AZ};
    \item i nodi devono essere assegnati all'anello in ordine di \texttt{AZ}, in modo da garantire che un intervallo di lunghezza \texttt{n} nell'anello contenga nodi appartenenti a \texttt{AZ} distinte.
\end{itemize}

\subsection{Limitazione del Throughput}
\label{subsec:limitazione-throughput}

In un sistema multi-tenant come Kitsurai, è necessario evitare che un singolo client monopolizzi le risorse e comprometta le prestazioni degli altri.
Per questo motivo, Kitsurai implementa un meccanismo di limitazione del throughput che garantisce a ogni client la banda richiesta al momento della creazione della tabella, anche in presenza di carichi elevati e concorrenti.

Ogni nodo del cluster mantiene, per ciascuna tabella, una variabile \texttt{sched\_at} che indica il momento in cui il nodo sarà nuovamente disponibile per eseguire nuove operazioni su quella tabella.
Quando un client invia una richiesta di lettura o scrittura, il nodo attende fino al tempo indicato da \texttt{sched\_at} prima di eseguire l'operazione, quindi incrementa \texttt{sched\_at} di un intervallo pari a $\displaystyle \frac{1}{b}$, dove $b$ rappresenta la banda richiesta per la tabella.
Se \texttt{sched\_at} è già passato, il sistema potrebbe eseguire operazioni incontrollate finché \texttt{sched\_at} non raggiunge il tempo corrente; per evitare ciò, se \texttt{sched\_at} è già passato, viene aggiornato a 100 ms prima del tempo corrente, permettendo così un breve burst controllato di operazioni.

\begin{samepage}
\noindent In pseudocodice, la limitazione del throughput può essere rappresentata come segue:
\begin{minted}{python}
def limit_throughput(table, operation):
    current_time = get_current_time()
    if table.sched_at > current_time - 0.1:
        table.sched_at = current_time - 0.1
    run_at = table.sched_at
    table.sched_at += 1 / table.bandwidth
    wait_until(run_at)
    execute_operation(operation)
\end{minted}
\end{samepage}

\subsection{Allocazione della Banda}
\label{subsec:allocazione-banda}

Per l'allocazione della banda, Kitsurai adotta un modello molto semplice: si assume che il numero massimo di operazioni al secondo eseguibili da una macchina sia fisso e indipendente da altri fattori come la dimensione delle letture e scritture in corso.

Per questo motivo, a ciascun nodo è sufficiente conoscere la banda massima - misurata in precedenza utilizzando operazioni di dimensione standard - per determinare se sia in grado o meno di gestire il carico richiesto da una tabella.
A tal fine, è necessario l'impiego di dischi SSD, in quanto garantiscono prestazioni costanti e prevedibili, a differenza degli HDD, soggetti a rallentamenti imprevedibili dovuti a operazioni di seek e latenza di accesso.

\subsection{Remote Procedure Calls}
\label{subsec:rpc}

Kitsurai utilizza un protocollo di Remote Procedure Call (RPC) per la comunicazione tra i nodi del cluster.
Una richiesta RPC avviene tramite una connessione TCP tra i due nodi, il nodo mittente utilizza, se disponibile, una connessione pre-esistente, altrimenti ne apre una nuova.
Richiesta e riposta RPC sono serializzate in un formato \emph{length-prefixed}, che consente di inviare un prefisso contenente la lunghezza della richiesta o risposta, seguito dai dati serializzati.
Conclusa la richiesta, la connessione TCP viene mantenuta aperta e viene resa disponibile per ulteriori richieste RPC, riducendo il costo di apertura e chiusura delle connessioni.

In pseudocodice, una richiesta RPC può essere rappresentata come segue:
\begin{minted}{python}
def rpc_request(node, request):
    connection = node.get_open_connection()
    if connection is None:
        connection = node.open_new_connection()

    serialized_request = serialize(request)
    connection.send(int_to_bytes(len(serialized_request), 8))
    connection.send(serialized_request)

    response_length = int_from_bytes(connection.recv(8))
    response_data = connection.recv(response_length)
    node.put_open_connection(connection)

    return deserialize(response_data)
\end{minted}

\subsection{Librerie}
\label{subsec:librerie}

Kitsurai utilizza diverse librerie per implementare le funzionalità del sistema, le più rilevanti sono:
\begin{itemize}
    \item \texttt{tokio}\footnote{\url{https://tokio.rs/}}: gestione della concorrenza e operazioni asincrone.
    \item \texttt{axum}\footnote{\url{https://crates.io/crates/axum}}: gestione delle richieste HTTP e creazione di server web.
    \item \texttt{serde}\footnote{\url{https://serde.rs/}} e \texttt{postcard}\footnote{\url{https://crates.io/crates/postcard}}: serializzazione e deserializzazione dei dati nelle richieste e risposte RPC.
    \item \texttt{uuid}\footnote{\url{https://crates.io/crates/uuid}}: generazione e gestione degli UUID delle tabelle.
    \item \texttt{xxhash-rust}\footnote{\url{https://crates.io/crates/xxhash-rust}}: calcolo degli hash delle chiavi, utilizzando l'algoritmo \texttt{XXH3}.
    \item \texttt{clap}\footnote{\url{https://crates.io/crates/clap}}: gestione della riga di comando e parametri di configurazione.
\end{itemize}
